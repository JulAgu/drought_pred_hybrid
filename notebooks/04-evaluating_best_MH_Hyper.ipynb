{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A dirty little trick to avoid having to deal with the notion of relative path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/juagudelo/HOMEdev/drought_pred_hybrid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juagudelo/HOMEdev/drought_pred_hybrid'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here, this notebook is going to be used to evaluate the best model issued from the hyperparameter tuning over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import f1_score, mean_absolute_error\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import models\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing a seed to warrant the reproducibility\n",
    "torch.manual_seed(21)\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "num_categorical_features=7\n",
    "num_numerical_features=22\n",
    "num_time_series_features=21\n",
    "batch_size=128\n",
    "output_weeks=6\n",
    "# Hyperparameters\n",
    "num_epochs_entire=3\n",
    "hidden_size= 160\n",
    "num_lstm_layers= 5\n",
    "embedding_dims= 250\n",
    "num_fc_tabular_layers= 2\n",
    "num_fc_combined_layers= 5\n",
    "dropout= 0.2\n",
    "learning_rate= 5.414458430824775e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the list of unique categories for the categorical features\n",
    "with open(f\"data/processed_dataFrames/list_cat.pickle\", \"rb\") as f:\n",
    "    list_cat = pickle.load(f)\n",
    "\n",
    "# Importing the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the loaders\n",
    "dfs=utilities.load_dataFrames()\n",
    "valid_loader=utilities.create_dataLoader(X_static=dfs[\"X_tabular_valid\"],\n",
    "                                         X_static_cat=dfs[\"X_tabular_cat_valid\"],\n",
    "                                         X_time=dfs[\"X_time_valid\"],\n",
    "                                         y_target=dfs[\"y_target_valid\"],\n",
    "                                         output_weeks=output_weeks,\n",
    "                                         y_past=None,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=False\n",
    "                                         )\n",
    "test_loader=utilities.create_dataLoader(X_static=dfs[\"X_tabular_test\"],\n",
    "                                        X_static_cat=dfs[\"X_tabular_cat_test\"],\n",
    "                                        X_time=dfs[\"X_time_test\"],\n",
    "                                        y_target=dfs[\"y_target_test\"],\n",
    "                                        output_weeks=output_weeks,\n",
    "                                        y_past=None,\n",
    "                                        batch_size=128,\n",
    "                                        shuffle=False\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "NVIDIA T1000 8GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63997/1993821846.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"models/MH_Hyper/MH_Hyper_1.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HybridModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0-4): 5 x Embedding(7, 250)\n",
       "    (5): Embedding(6, 250)\n",
       "    (6): Embedding(8, 250)\n",
       "  )\n",
       "  (tabular_fc_layers): Sequential(\n",
       "    (0): Linear(in_features=1772, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (lstm): LSTM(21, 160, num_layers=5, batch_first=True)\n",
       "  (attention): Linear(in_features=160, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc_after_context): Linear(in_features=160, out_features=64, bias=True)\n",
       "  (combined_fc_layers): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the device\n",
    "device=torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.get_device_name(device=None))\n",
    "\n",
    "model = models.HybridModel(num_categorical_features,\n",
    "                           list_cat,\n",
    "                           num_numerical_features,\n",
    "                           num_time_series_features,\n",
    "                           hidden_size,\n",
    "                           num_lstm_layers,\n",
    "                           dropout,\n",
    "                           embedding_dims,\n",
    "                           num_fc_tabular_layers,\n",
    "                           num_fc_combined_layers,\n",
    "                           output_size=output_weeks,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/MH_Hyper/MH_Hyper_1.pt\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, static, static_cat):\n",
    "    out = model(static_cat, static, x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation predictions...: 100%|██████████| 69/69 [00:06<00:00, 10.49it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_map = {\n",
    "    \"y_pred\": [],\n",
    "    \"y_pred_rounded\": [],\n",
    "    # \"fips\": [],\n",
    "    # \"date\": [],\n",
    "    \"y_true\": [],\n",
    "    \"week\": [],\n",
    "}\n",
    "i = 0\n",
    "for static, static_cat, x, y in tqdm(\n",
    "    test_loader,\n",
    "    desc=\"Test predictions...\",\n",
    "):\n",
    "    x, static, y = x.to(device), static.to(device), y.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = predict(x, static, static_cat).clone().detach()\n",
    "    for w in range(output_weeks):\n",
    "        dict_map[\"y_pred\"] += [float(p[w]) for p in pred]\n",
    "        dict_map[\"y_pred_rounded\"] += [int(p.round()[w]) for p in pred]\n",
    "        # dict_map[\"fips\"] += [f[1][0] for f in valid_fips[i : i + len(x)]]\n",
    "        # dict_map[\"date\"] += [f[1][1] for f in valid_fips[i : i + len(x)]]\n",
    "        dict_map[\"y_true\"] += [float(item[w]) for item in y]\n",
    "        dict_map[\"week\"] += [w] * len(x)\n",
    "    i += len(x)\n",
    "df = pd.DataFrame(dict_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_rounded</th>\n",
       "      <th>y_true</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.884420</td>\n",
       "      <td>2</td>\n",
       "      <td>2.8891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.515110</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.479904</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52603</th>\n",
       "      <td>1.178136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52604</th>\n",
       "      <td>1.282593</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52605</th>\n",
       "      <td>0.006253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52606</th>\n",
       "      <td>0.006797</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52607</th>\n",
       "      <td>1.634603</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2276</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52608 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         y_pred  y_pred_rounded  y_true  week\n",
       "0      1.884420               2  2.8891     0\n",
       "1      0.000700               0  0.8519     0\n",
       "2      0.000645               0  0.0000     0\n",
       "3      1.515110               2  1.4617     0\n",
       "4      1.479904               1  1.6942     0\n",
       "...         ...             ...     ...   ...\n",
       "52603  1.178136               1  0.0000     5\n",
       "52604  1.282593               1  2.0000     5\n",
       "52605  0.006253               0  0.0000     5\n",
       "52606  0.006797               0  0.0000     5\n",
       "52607  1.634603               2  3.2276     5\n",
       "\n",
       "[52608 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 1 MAE 0.143 F1 0.677\n",
      "Week 2 MAE 0.198 F1 0.574\n",
      "Week 3 MAE 0.246 F1 0.513\n",
      "Week 4 MAE 0.289 F1 0.471\n",
      "Week 5 MAE 0.325 F1 0.428\n",
      "Week 6 MAE 0.357 F1 0.403\n"
     ]
    }
   ],
   "source": [
    "for w in range(6):\n",
    "    wdf = df[df['week']==w]\n",
    "    mae = mean_absolute_error(wdf['y_true'], wdf['y_pred']).round(3)\n",
    "    f1 = f1_score(wdf['y_true'].round(),wdf['y_pred'].round(), average='macro').round(3)\n",
    "    print(f\"Week {w+1}\", f\"MAE {mae}\", f\"F1 {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
