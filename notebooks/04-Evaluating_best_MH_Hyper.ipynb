{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A dirty little trick to avoid having to deal with the notion of relative path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/juagudelo/HOMEdev/drought_pred_hybrid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juagudelo/HOMEdev/drought_pred_hybrid'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here, this notebook is going to be used to evaluate the best model issued from the hyperparameter tuning over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import f1_score, mean_absolute_error\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import models\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing a seed to warrant the reproducibility\n",
    "torch.manual_seed(21)\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "num_categorical_features=7\n",
    "num_numerical_features=22\n",
    "num_time_series_features=21\n",
    "batch_size=128\n",
    "output_weeks=6\n",
    "# Hyperparameters\n",
    "hidden_size= 340\n",
    "num_lstm_layers= 8\n",
    "embedding_dims= 270\n",
    "num_fc_tabular_layers= 4\n",
    "num_fc_combined_layers= 1\n",
    "dropout= 0.30000000000000004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the list of unique categories for the categorical features\n",
    "with open(f\"data/processed_dataFrames/list_cat.pickle\", \"rb\") as f:\n",
    "    list_cat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the loaders\n",
    "dfs=utilities.load_dataFrames()\n",
    "valid_loader=utilities.create_dataLoader(X_static=dfs[\"X_tabular_valid\"],\n",
    "                                         X_static_cat=dfs[\"X_tabular_cat_valid\"],\n",
    "                                         X_time=dfs[\"X_time_valid\"],\n",
    "                                         y_target=dfs[\"y_target_valid\"],\n",
    "                                         output_weeks=output_weeks,\n",
    "                                         y_past=None,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=False\n",
    "                                         )\n",
    "test_loader=utilities.create_dataLoader(X_static=dfs[\"X_tabular_test\"],\n",
    "                                        X_static_cat=dfs[\"X_tabular_cat_test\"],\n",
    "                                        X_time=dfs[\"X_time_test\"],\n",
    "                                        y_target=dfs[\"y_target_test\"],\n",
    "                                        output_weeks=output_weeks,\n",
    "                                        y_past=None,\n",
    "                                        batch_size=128,\n",
    "                                        shuffle=False\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "NVIDIA T1000 8GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HybridModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0-4): 5 x Embedding(7, 270)\n",
       "    (5): Embedding(6, 270)\n",
       "    (6): Embedding(8, 270)\n",
       "  )\n",
       "  (tabular_fc_layers): Sequential(\n",
       "    (0): Linear(in_features=1912, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (lstm): LSTM(21, 340, num_layers=8, batch_first=True)\n",
       "  (attention): Linear(in_features=340, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.30000000000000004, inplace=False)\n",
       "  (fc_after_context): Linear(in_features=340, out_features=64, bias=True)\n",
       "  (combined_fc_layers): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the device\n",
    "device=torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.get_device_name(device=None))\n",
    "\n",
    "model = models.HybridModel(num_categorical_features,\n",
    "                           list_cat,\n",
    "                           num_numerical_features,\n",
    "                           num_time_series_features,\n",
    "                           hidden_size,\n",
    "                           num_lstm_layers,\n",
    "                           dropout,\n",
    "                           embedding_dims,\n",
    "                           num_fc_tabular_layers,\n",
    "                           num_fc_combined_layers,\n",
    "                           output_size=output_weeks,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/MH_Hyper/MH_Hyper_12.pt\", weights_only=True))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, static, static_cat):\n",
    "    out = model(static_cat, static, x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test predictions...: 100%|██████████| 69/69 [00:43<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_map = {\n",
    "    \"y_pred\": [],\n",
    "    \"y_pred_rounded\": [],\n",
    "    # \"fips\": [],\n",
    "    # \"date\": [],\n",
    "    \"y_true\": [],\n",
    "    \"week\": [],\n",
    "}\n",
    "i = 0\n",
    "for static, static_cat, x, y in tqdm(\n",
    "    test_loader,\n",
    "    desc=\"Test predictions...\",\n",
    "):\n",
    "    x, static, y = x.to(device), static.to(device), y.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = predict(x, static, static_cat).clone().detach()\n",
    "    for w in range(output_weeks):\n",
    "        dict_map[\"y_pred\"] += [float(p[w]) for p in pred]\n",
    "        dict_map[\"y_pred_rounded\"] += [int(p.round()[w]) for p in pred]\n",
    "        # dict_map[\"fips\"] += [f[1][0] for f in valid_fips[i : i + len(x)]]\n",
    "        # dict_map[\"date\"] += [f[1][1] for f in valid_fips[i : i + len(x)]]\n",
    "        dict_map[\"y_true\"] += [float(item[w]) for item in y]\n",
    "        dict_map[\"week\"] += [w] * len(x)\n",
    "    i += len(x)\n",
    "df = pd.DataFrame(dict_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_rounded</th>\n",
       "      <th>y_true</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.056026</td>\n",
       "      <td>2</td>\n",
       "      <td>2.8891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.329628</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.090850</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.557501</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.936767</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52603</th>\n",
       "      <td>1.076862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52604</th>\n",
       "      <td>1.719404</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52605</th>\n",
       "      <td>0.186367</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52606</th>\n",
       "      <td>0.218914</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52607</th>\n",
       "      <td>2.509225</td>\n",
       "      <td>3</td>\n",
       "      <td>3.2276</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52608 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         y_pred  y_pred_rounded  y_true  week\n",
       "0      2.056026               2  2.8891     0\n",
       "1      0.329628               0  0.8519     0\n",
       "2      0.090850               0  0.0000     0\n",
       "3      1.557501               2  1.4617     0\n",
       "4      0.936767               1  1.6942     0\n",
       "...         ...             ...     ...   ...\n",
       "52603  1.076862               1  0.0000     5\n",
       "52604  1.719404               2  2.0000     5\n",
       "52605  0.186367               0  0.0000     5\n",
       "52606  0.218914               0  0.0000     5\n",
       "52607  2.509225               3  3.2276     5\n",
       "\n",
       "[52608 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 1 MAE 0.131 F1 0.758\n",
      "Week 2 MAE 0.198 F1 0.647\n",
      "Week 3 MAE 0.239 F1 0.595\n",
      "Week 4 MAE 0.291 F1 0.559\n",
      "Week 5 MAE 0.33 F1 0.514\n",
      "Week 6 MAE 0.369 F1 0.476\n"
     ]
    }
   ],
   "source": [
    "for w in range(6):\n",
    "    wdf = df[df['week']==w]\n",
    "    mae = mean_absolute_error(wdf['y_true'], wdf['y_pred']).round(3)\n",
    "    f1 = f1_score(wdf['y_true'].round(),wdf['y_pred'].round(), average='macro').round(3)\n",
    "    print(f\"Week {w+1}\", f\"MAE {mae}\", f\"F1 {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
